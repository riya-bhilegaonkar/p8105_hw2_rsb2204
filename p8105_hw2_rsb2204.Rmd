---
title: "Homework 2"
author: "Riya Bhilegaonkar"
date: "2022-10-01"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Problem 0

```{r load_libraries}
library(tidyverse)
library(readxl)
```

### Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. 

```{r}
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

This dataset contains data points on NYC transit data, the variables the dataset contains is line, station_line, station_langitude, station_longitude, route1 to route11, entry, exit_only, vending, entrance_type and ada. The dimension of the dataset is 1868 X 20.
To obtain a tidy dataset we would need to convert `route` variables from wide to long format. To clean up the dataset upon import, we update variable names, and select columns that will be used in the questions and update the `entry` variable to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character vectors for consistency with 1-7.

The distinct stations can be found using the below code chunk:
```{r}
q1 = trans_ent %>% 
  select(station_name, line) %>% 
  distinct
nrow(q1)
```

There are 465 distinct stations.

The number of stations that are ADA compliant are found using the below code chunk:

```{r}
q2 <- trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct

nrow(q2)
```

There are 84 stations that are ADA compliant.


The proportion of station entrances / exits without vending allow entrance?

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Reformating the data so that the route number and route name are distinct variables. The number of distinct stations that serve the A train and the number that are ADA compliant are found using the below code.

```{r}
q3 <- trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
nrow(q3)

q4 <- trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct

nrow(q4)
```

The number of distinct stations that serve the A train is 60. The number of stations that serve the A train, that are ADA compliant is 17.

### Problem 2
Reading and cleaning the Mr. Trash Wheel sheet:
```{r}
mr.trash_wheel = read_excel("data/Trash Wheel Collection Data.xlsx", sheet="Mr. Trash Wheel")%>%
  janitor::clean_names() %>%
  select(-x15, -x16) %>% 
  mutate(year = as.double(year),sports_balls = as.integer(sports_balls), mr = "yes") %>% drop_na(dumpster)


```

Reading and cleaning the Professor Trash Wheel sheet:
```{r}
prof.trash_wheel = read_excel("data/Trash Wheel Collection Data.xlsx", sheet=2) %>%
  janitor::clean_names() %>%
  mutate(prof = "yes" ) %>%
  drop_na(dumpster)
```

Combining the two datasets:
```{r}
trash_wheel = full_join(mr.trash_wheel, prof.trash_wheel)

```

The combined dataset results in data points from the the Mr. Trash Wheel (a water-wheel vessel) and Professor Trash Wheel dataset .This includes data on variables such as the dumpster number, date or collection, amount of total litter (weight in tons and volume in cubic yards), litter type (plastic bottles, polystyrene, cigarette butts, glass bottles, grocery bags, chip bags, sports balls) and number of homes powered. The total number of observations in the resulting dataset is `r nrow(trash_wheel)`. An example of a key variable is `weight_tons` where the values represent the weight of trash collected by Mr. Trash Wheel or Professor Trash Wheel in tons.

The total weight of trash collected by professor trash wheel is `r sum(prof.trash_wheel$weight_tons)`.

The total number of sports balls collected by Mr. Trash Wheel in 2020 is `r mr.trash_wheel %>% filter(year==2020) %>%summarise(sum_ball = sum(sports_balls))`.

### Problem 3

Cleaning the data in `pols-month.csv`
```{r}
pols = read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>% 
  separate(mon, c("year", "month", "day")) %>% 
  mutate("month" = as.integer(month), "year"=as.integer(year), "month" = month.abb[month], president = ifelse(prez_gop == 1, "gop","dem")) %>% 
  select(-prez_dem, -prez_gop, -day)

```

Cleaning the data in `snp.csv`
```{r}
snp = read_csv("data/fivethirtyeight_datasets/snp.csv") %>% 
  separate(date, c("month", "day", "year")) %>% 
  mutate("month" = as.integer(month), "month" = month.abb[month],"year"=as.integer(year), year = ifelse(year > 15, year+1900, year+2000)) %>% 
  select(-day) %>% 
  arrange(year, month) %>% 
  select(year, month, close)

```

Tidying the `unemployment.csv` data:
```{r}
unemployment = read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
janitor::clean_names() %>%
pivot_longer(jan:dec, names_to="month", values_to="unemployment") %>% 
  mutate(month = str_to_title(month))

```


Joining the datasets by merging `snp` into `pols`:
```{r}
snp_pols = left_join(pols, snp, by=c("year","month"))
```

Now merging `unemployment` in `snp_pols`:
```{r}
problem_3 = left_join(snp_pols, unemployment, by=c("year","month"))
```

The final resulting dataset has `r nrow(problem_3)` observations. The dataset of `pol` contains information related to the number of national politicians who were democratic or republic and whether the president was a democrat or republican for a given month and year. The size of the `pol` dataset is 822 rows X 9 variables, a key variable in the dataset was `president`, the range of years is 1947-1950.  The `snp` dataset gives the closing value of the S&P stock index for a given month and date. The size of the `snp` dataset is 787 rows X 3 variables, a key variable here is `close`, the range of years is 1950-2015. The `unemployment` dataset contains the percentages of unemployment for the given month and year. The dimensions of the `unemployment`dataset is 816 rows X 3 variables, a key variable is `unemployment`, the range of years is 1948-2015. The result dataset which is `problem_3` contains columns from the 3 other datasets, joined by the variables of `month` and `year`. The size of the dataset is 822 rows X 11 variables, key variables include `employment`, `president`, `close`, `gov_gop` etc. The range of years is the full range of all three datasets which is 1947-2015, coinciding with the `pols` dataset as the other two datasets are merged into it.

